{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import utils\n",
    "def read_corpus(fname):\n",
    "    for line in open(fname,encoding = 'utf-8'):\n",
    "        yield utils.simple_preprocess(line)\n",
    "\n",
    "# 50000_WoS.txt\n",
    "# 50000_MedLine.txt\n",
    "docs = list(read_corpus('../datasets/50000_MedLine.txt'))\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disruption management for vehicle routing problem with the request changes of customers to tackle the disruption caused by the requests of the customers in the logistics the disruption recovery solution is given based on the theory of disruption management the transformation method for the disruption recovery of the vehicle routing problem is proposed on the basis of single depot and the disruption recovery strategies and the methods of deviation measurement are given which is the basis of the disruption management modeling for the vehicle routing problem for the disruption management of vehicle routing problem with the request changes of customers the disruption is illustrated the disruption management model is constructed and the normalization processing for the model is given making the model compatible with vrptw on the basis of the characteristic of model the chromosome code based on customer is ameliorated according to the disruption management the genetic algorithm is designed representative result and the analysis are given in this paper and the experiment indicates the validity of the model and algorithm'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [[]*len(docs) for x in range(len(docs))]\n",
    "for i in range(len(docs)):\n",
    "    corpus[i] = ' '.join(docs[i])\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vectorizer = CountVectorizer()    \n",
    "transformer = TfidfTransformer()  \n",
    "\n",
    "vec_matrix = vectorizer.fit_transform(corpus)           # Convert text into a word frequency matrix\n",
    "tfidf_model = transformer.fit_transform(vec_matrix)   # Calculate tf-idf\n",
    "\n",
    "weight = tfidf_model.toarray()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 8384,\n",
       "         7: 7553,\n",
       "         9: 7710,\n",
       "         8: 13873,\n",
       "         1: 10017,\n",
       "         4: 6442,\n",
       "         5: 6858,\n",
       "         3: 5891,\n",
       "         0: 9624,\n",
       "         6: 3648})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "classNumber = 10\n",
    "kmean_model = KMeans(n_clusters = classNumber).fit(weight)\n",
    "labels = kmean_model.labels_\n",
    "\n",
    "from collections import Counter\n",
    "center_dict = Counter(labels)\n",
    "center_dict\n",
    "# 393.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth_label():\n",
    "    ground_truth_label = []\n",
    "    # 50000_WoS_WC\n",
    "    # 50000_MedLine_Label\n",
    "    with open('../datasets/50000_MedLine_Label.txt','r',encoding = 'utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = int(line.replace('\\n',''))\n",
    "            ground_truth_label.append(line)\n",
    "    return ground_truth_label\n",
    "ground_truth_label = get_ground_truth_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6322012659686738\n",
      "0.6717251546791112\n",
      "0.7112289254197842\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.adjusted_rand_score(labels, ground_truth_label))\n",
    "print(metrics.fowlkes_mallows_score(labels, ground_truth_label))\n",
    "print(metrics.adjusted_mutual_info_score(labels, ground_truth_label))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4905652b14e4b7eb92899b78ac499a22c488804455b27940a322fd82aaf71031"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
